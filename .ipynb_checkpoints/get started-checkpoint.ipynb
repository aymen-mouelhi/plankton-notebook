{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plankton 2.0 Challenge Tutorial\n",
    "![plankton](https://68.media.tumblr.com/avatar_5d78d8a8ae8e_128.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Welcome to the Plantkon 2.0 Challenge origanized by SAP! In this notebook, we provide an introduction to the wonderful plankton world together with a more or less detailed description of the datasets. Besides, we provide a tutorial to classify plankton images using Random Forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The SAP Next-Gen program is an innovation platform for the SAP ecosystem enabling companies, partners and universities to connect and innovate with purpose linked to the UN Global Goals. Reimagine the future of industries with exponential technologies. Seed in disruptive innovation with startups. Build skills for digital futures. Showcase thought leadership.\n",
    "\n",
    "The program leverages a network of 3,300+ educational institutions in 111 countries that are members of the SAP University Alliances and SAP Young Thinkers programs.\n",
    "\n",
    "In this challenge we will try to tackle the SAP's global goal 14: **Life Below Water**, the aim of this goal is to conserve and sustainably use the oceans, seas, and marine resources for sustainable development.\n",
    "\n",
    "The Oceanographic Observatory of Villefranche-sur-Mer was established in 1882 by Hermann Fol with the encouragement of Charles Darwin and has a world-wide reputation in  plankton research and also is one of the most “Data Science” aware geo sciences research centres. The observatory has collected about 50 million images of plankton from all over the world with 20 million of them already labelled and ready for use.\n",
    "\n",
    "The purpose of the challenge is to create a prototype of a new application which will show practical usage of “plankton data” for general public or for industry, using the attributes of plankton images and plankton ability to predict water/air quality.\n",
    "\n",
    "The teams will be formed at the beginning of the challenge and will consist of the students from different schools representing different skills (business, data science, coding) and helped by SAP developers. The Design thinking sessions will start the teams off on a path of new and inventive applications!\n",
    "\n",
    "This document is devided into 4 sections:\n",
    "* Description of the role of plankton as a great bioindicator\n",
    "* Description of the tools that we will be using (open source and SAP tools)\n",
    "* Introduction and description of the data sets\n",
    "* Playground with the plankton images data (Technical)\n",
    "\n",
    "\n",
    "## 1- Challenge Context\n",
    "\n",
    "### Bioindicators\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "Naturally occurring Bioindicators are used to assess the health of the environment and are also an important tool for detecting changes in the environment, either positive or negative, and their subsequent effects on human society. There are a certain factors which govern the presence of Bioindicators in environment such as transmission of light, water, temperature, and suspended solids. Through the application of Bioindicators we can predict the natural state of a certain region or the level/degree of contamination. The advantages associated with using Bioindicators are as follows:\n",
    "\n",
    "- Biological impacts can be determined.\n",
    "- To monitor synergetic and antagonistic impacts of various pollutants on a creature.\n",
    "- Early stage diagnosis as well as harmful effects of toxins to plants, as well as human beings, can be monitored.\n",
    "- Can be easily counted, due to their prevalence.\n",
    "- Economically viable alternative when compared with other specialized measuring systems.\n",
    "\n",
    "#### Utilization of Bioindicators\n",
    "\n",
    "The expression ‘Bioindicator’ is used as an aggregate term referring to all sources of biotic and abiotic reactions to ecological changes. Instead of simply working as gauges of natural change, taxa are utilized to show the impacts of natural surrounding changes, or environmental change. They are used to detect changes in natural surroundings as well as to indicate negative or positive impacts. They can also detect changes in the environment due to the presence of pollutants which can affect the biodiversity of the environment, as well as species present in it. \n",
    "\n",
    "The condition of the environment is effectively monitored by the use of Bioindicator species due to their resistance to ecological variability. Hasselbach et al. utilized the moss i.e. Hylocomium splendens as a natural indicator of heavy metals in the remote tundra environment of northwestern Alaska. Here, the ore of mineral is mined from Red Dog Mine, the world’s largest creator of zinc (Zn), and is carried to a singular street (∼75 km long) to storage spaces on the Chukchi Sea. Hasselbach and her partners inspected whether this overland transport was influencing the encompassing physical biota. The contents of heavy metals inside the moss tissue were analyzed at different distances from the street. The concentrations of metals in moss tissue were most prominently adjacent to the haul street and reduced with distance, therefore supporting the theory that overland transport was in fact modifying the encompassing environment. In this study, lichens were utilized as biomonitors by utilizing the quantitative estimation of metal concentrations inside individual lichen.\n",
    "\n",
    "Natural, biological, and biodiversity markers can be found in various organisms occupying different types of environments. Lichens (a symbiosis among Cyano bacteria, algae, and/or fungi) and Bryophytes (liverworts) are frequently used to monitor air contamination. Both, Lichens and Bryophytes are powerful Bioindicators of air quality on the grounds that they have no roots, no fingernail skin, and acquire all their supplements from immediate introduction to the climate. Their high surface region to volume ratio further supports the theory of their use as a bioindicator, or supports their ability to capture contaminates from the air. Cynophyta, a type of phytoplankton, is one particularly powerful bioindicator which is known to indicate rapid eutrophication of water bodies such as reservoirs, lakes, etc. via the creation of bloom formations\n",
    "\n",
    "#### Biomonitoring\n",
    "\n",
    "Bio-organisms are basically used to define the characteristics of a biosphere. These organisms are known as Bioindicators or biomonitors, both of which may vary considerably. When studying the environment the quality of changes taking place can be determined by Bioindicators while biomonitors are used to get quantitative information on the quality of the environment biological monitoring also incorporating data regarding past aggravations and the impacts of various variables.\n",
    "\n",
    "Monitoring can be done for various biological processes or systems with the objective of observing the temporal and spatial changes in health status, assessing the impacts of specific environment or anthropogenic stressors and assessing the viability of anthropogenic measures (e.g. reclamation, remediation, and reintroduction). The species diversity is used as a prime aspect in biological monitoring, which is considered to be a valuable parameter in determining the health of the environment.\n",
    "\n",
    "Biomonitoring is one of the essential components for assessing the quality of water and has become an integral element of conducting studies on water pollution. Biomonitors are freely available all around the world. They fundamentally mirror the natural impact over creatures and can be used and understood with minimum preparation and training. Despite the fact that all natural species can be considered biomonitors to some degree, the above focal points applies well to planktons and similar species type, when water pollution is considered.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plankton\n",
    "![whale food](images/whale_food.png)\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "In many water bodies, such as, seas, lakes, streams, and swamps, significant biological production is carried out by plankton. Planktons are composed of organisms with chlorophyll (i.e. phytoplankton and animals such as zooplanktons). These planktons consist of communities that float along currents and tides, yet they fuse and cycle important quantities of energy that is then passed on to higher trophic levels (Walsh 1978).\n",
    "\n",
    "Planktons react rapidly to ecological changes and are viewed as excellent indicators of water quality and trophic conditions due to their short time and rapid rate of reproduction. Under natural conditions, the occurrence of planktonic organisms is identified with the resistance range in relation to abiotic ecological components (Temperature, Oxygen fixation, and pH) as well as the biotic connections among organisms. The changes that occur within the communities of planktons provide the platform to determine the trophic state of water bodies.\n",
    "\n",
    "![need](https://kaggle2.blob.core.windows.net/competitions/kaggle/3978/media/Plankton-Diagram3-lg.png)\n",
    "\n",
    "#### Planktons as an indicator of water pollution\n",
    "\n",
    "Since planktons are profoundly sensitive to natural change they are best markers of water quality and particularly sea conditions. One of the reasons planktons are being considered in seas is to monitor the water quality of the lake when there are high centralizations of phosphorus and nitrogen; these centralizations may be indicated by certain planktons reproducing at an increased rate. This is evidence of poor water quality that may influence other organisms living in the water body. In addition to being a health indicator, planktons are also the fundamental sustenance for many larger organisms in the sea. Thus the plankton is key to the marine organisms, as both an indicator of water quality and as the main food source for many fish.\n",
    "\n",
    "Plankton also plays an important role in biological deterioration organic matter; but if plankton populations are too large this creates other problems in managing the water body. Fish at this critical stage of ecological process play an important role by grazing the planktons. The two roles played by fish are very crucial as they help in maintaining the proper balance of planktons in the pond and convert the nutrient available in wastewater into a form which is consumable by humans. Additionally, certain planktons such as cyanobacteria produce toxins which are harmful for fish growth. Thus planktons can be termed as useful or harmful, with respect to wastewater fed production of fishes.\n",
    "\n",
    "![indicator](http://www.tandfonline.com/na101/home/literatum/publisher/tandf/journals/content/tfls20/2016/tfls20.v009.i02/21553769.2016.1162753/20160621/images/medium/tfls_a_1162753_f0004_b.gif)\n",
    "\n",
    "#### Phytoplankton\n",
    "\n",
    "Phytoplanktons, also known as microalgae, are similar to terrestrial plants in that they contain chlorophyll and require daylight to live and develop. Most are light and swim in the upper portion of the sea, where light infiltrates the water. Development and photosynthesis are closely related, each one being a function of usage of light and food supplements. Algae are quite sensitive to contamination, and this may be reflected in their population levels and/or rates or photosynthesis Affects development of population or photosynthesis, for the most part, algae are as sensitive to contaminations as other species. When there is change in the diversity of phytoplankton species, it may indicate pollution of the marine ecosystem.\n",
    "\n",
    "##### Evidences pertaining to phytoplankton\n",
    "\n",
    "Phytoplanktons have been used for successful observation of water contamination and are a useful indicator of water quality. \n",
    "In 1975, Dugdale depicted the relationship of the growth rate of an algal population, photosynthesis, and nutrient concentration in the water body. Contaminations can influence the connection between rate of growth and each of these variables. For example, if there is an industrial effluent which is colored or contains suspended solids light may be filtered or absorbed causing a reduction in rate of growth. Macisaacand and Dugdale in 1976 showed that a decrease of light leads to decrease in rate of uptake of ammonia and nitrate in marine phytoplankton.\n",
    "\n",
    "Overnell et al. demonstrated that light prompted oxygen evolution from the freshwater species Chlamydomonas reinhardtii was sensitive to cadmium, methyl mercury, and lead. Moore et al. discovered that organo-chlorine compounds decrease use of bicarbonate by estuarine phytoplankton. Whitacre et al. also produced significant research on the effect of numerous chlorinated hydrocarbons on fixation of carbon by phytoplankton.\n",
    "\n",
    "Phytoplanktons are also an important source of pollutant transfer from water to upper tropic levels and even to humans. Algae are unable to decompose the pesticides and are thus a link of transfer to herbivores when fed upon. Substances gathering and intake plays an important role in pollution dynamics of phytoplankton. If light is obstructed, it hampers the intake of ammonia and nitrate by aquatic phytoplankton as indicated by Mac Isaac and Dugdale, especially when the industrial colored or solid suspended waste accumulates on the water surface which results in reduction of growth rate, filtrations, and absorption of light.\n",
    "\n",
    "\n",
    "| Names of phytoplankton                        |             Indications            |\n",
    "| :--------------------------------------------:|:----------------------------------:|\n",
    "| Reen algae                                    |Facilitates the growth of fishes    |\n",
    "| Mosses, liverworts                            |Pollution by accumulation of metals |\n",
    "| Charophytes                                   |Quality of water                    |\n",
    "| Selanastrum                                   |Water pollution                     |\n",
    "| Wolffiaglobose                                |Contamination of cadmium            |\n",
    "| Euglena gracilis                              |Organic pollution in lakes                                        |\n",
    "| Chlorella vulgaris                            |Helps in removal of heavy metal contamination from water and soil |\n",
    "| Chlorococcales like C.vulgaris and A.falcatus |Indicators of the paper industry and sewage waste                 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Zooplanktons\n",
    "\n",
    "Zooplanktons are microscopic animals living near to the surface of the water body. They are poor swimmers, instead relying on tides and currents as a transport mechanism. They feed upon phytoplanktons, bacterioplanktons, or detritus (i.e. marine snow). Zooplanktons constitute a vital food source for fish. They also play an important role as Bioindicators and help to evaluate the level of water pollution. In freshwater communities, along with fish, they are the main food supplement to many other marine species.\n",
    "\n",
    "They are assumed to be a vital part in indicating water quality, eutrophication, and production of a freshwater body. In order to determine the status of a freshwater body it is necessary to measure seasonal variations and presence of zooplanktons.\n",
    "\n",
    "Differing varieties of species, biomass diversity and wealth of zooplankton groups can be utilized to determine the strength of a biological system. The potential of zooplankton as a bioindicator species is high on the grounds that their development and conveyance are subject to some abiotic (e.g. temperature, saltiness, stratification, and pollutants) and biotic parameters (e.g. limitation of food, predation, and competition).\n",
    "\n",
    "##### Evidences pertaining to zooplanktons\n",
    "\n",
    "Mechanical fermentation brought on a reduction in the quantity of species and changes in species strength, both of which were influenced as pH decreased from 7.0 to 3.8. Jha and Barat completed research on Lake Mirik, in Darjeeling, Himalayas, on zooplankton. This lake was polluted due to toxins let into the lake from outer sources resulting in a decreased pH in the lake and an increased acidity level. This was confirmed by the investigation of other physiochemical parameters and planktons. In this condition, cladocerans (Bosmina, Moina, and Daphnia) and copepods (Phyllodiaptomus and cylops the most extensive copepods) were found. This examination presumed that the lake cannot be utilized as a deficit for the supply of drinking water and these organisms served as a bioindicator to focus on the wellbeing of this oceanic body. As indicated by Siddiqi and Chandrasekhar, trichotria tetrat is could be utilized as contamination indicators as they were seen in the lake which was rich in phosphorus and other heavy metal particle. This species was obtained in the past in sewage-contaminated tanks. Phosphorous and metal particle as well as high aggregate alkanity, hardness, and high conductivity (130 ms m−1) of the lake water were restricting components for the development of zooplankton.\n",
    "\n",
    "Zooplankton may be present in an extensive variety of ecological conditions. Yet disintegrated oxygen, temperature, salinity, pH, and other physicochemical parameters are restricting elements. The vicinity of three types of Brachionussp indicates that the lake is being eutrophicated and is naturally contaminated. There is variation in the population of copepods, seasonally in various water bodies present in different parts of India; the seasonal studies of zooplanktons showed that the zooplanktons’ density was highest in the rainy season, while it reduced in summers due to high temperatures. Copepods form the dominant group of all the zooplanktons, followed by Cladocera, rotifer, and Ostrocoda. Ultimately, zooplankton has been found to be excellent an Bioindicator to evaluate the contamination of anyoceanic bodies (saltwater).\n",
    "\n",
    "| Names of zooplanktons                              |             Indications            |\n",
    "| :-------------------------------------------------:|:----------------------------------:|\n",
    "| Rotifers                                           |Trophic status    |\n",
    "| Keratellatropica, Hexarthramira                    |High turbidity due to suspended sediments |\n",
    "| Brachionuscalyciflorus                             |Eutrophic conditions and organic pollution of lakes   |\n",
    "| Cladocerans group (unspecified)                    |Low concentration of contaminants |\n",
    "| Trichotriatetratis                                 |Pollution caused by accumulation of phosphorous and heavy metal ions |\n",
    "| Thermocyclops, argyrodiaptomus                     |Eutrophic conditions  |\n",
    "| B.angularis, Rotatoria                             |Eutrophic conditions |\n",
    "| Leeches                                            |Indicates contamination because of presence of PCB (polychlorinated biphenyl) in a river |\n",
    "| Leeches                                            |Sensor-bioindicator of river contamination of PCB’s |\n",
    "| Oyster (Crassostreagigas), crabs (Geoticadepressa) |Presence of lead                |\n",
    "| B. dolabrotus                                      |High turbidity due to suspended sediments                 |\n",
    "| Copepods (Cyclops & phyllodiaptomus)               |Health of the marine body                 |\n",
    "| Cladocerans (moina, daphnia, bosmina)              |Health of the marine body                 |\n",
    "\n",
    "\n",
    "![Karen](https://vignette.wikia.nocookie.net/spongebob/images/c/c0/Plankton%27s_Diary_Karen.jpg/revision/latest/scale-to-width-down/320?cb=20150701035248)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Tools\n",
    "\n",
    "### Open Source\n",
    "\n",
    "You are free to use any programming language and any open source library, if you would like to play with the data we recommend Python and the following libraries:\n",
    "\n",
    "- Pandas\n",
    "- Numpy\n",
    "- Sickit-Learn\n",
    "\n",
    "\n",
    "### SAP\n",
    "\n",
    "\n",
    "#### Data Analysis and Prediction: SAP Predictive Analytics\n",
    "\n",
    "SAP Predictive Analytics is a powerfull tool from SAP that have many functional and technical capabilities:\n",
    "\n",
    "##### Functional Capabilities:\n",
    "\n",
    "- Automated analytics\n",
    "    - Let business analysts and data scientists use automated technique to build sophisticated predictive models that can be embedded in business processes – in days, not weeks or months.\n",
    "- Expert analytics\n",
    "    - Provide a modeling environment for open-source R-based algorithms, SAP HANA PAL, and SAP Automated Predictive Library (APL). Build predictive models with a powerful drag-and-drop interface, and allow users to use their own R scripts.\n",
    "- Model management\n",
    "    - Provide end-to-end model management, maintain peak performance for thousands of predictive models, and schedule updates as needed.\n",
    "    -Data Manager\n",
    "    - Data Manager provides a framework to facilitate automated data preparation. Users can define a broad set of reusable components, which can be applied to automatically create modeling data sets.\n",
    "- Predictive scoring\n",
    "    - Get individual variable contributions for every predictive model. Simulate, and score of a specific business question – in real time. Generate predictive scoring for a wide variety of target systems and directly embed the results.\n",
    "- Social and recommendation\n",
    "    - Run powerful network and link analysis to understand the connections and relationships between your customers – and discover which customers have a strong social influence. This capability can help you better manage churn, risk, and fraud.\n",
    "- Advanced Visualization\n",
    "    - Advanced Visualization provides an intuitive way to explore your data. Transform the results of applied predictive modeling into stunning, advanced visualizations that reveal actionable insights.\n",
    "    \n",
    "##### Technical Capabilities:\n",
    "\n",
    "- Predictive automation\n",
    "    - Support both SAP and non-SAP environments.\n",
    "- Big Data analytics\n",
    "    - Automate the building of predictive models based on data stored in Hadoop. Do data manipulation, model training, and retraining directly on Hadoop data using the Spark engine.\n",
    "- Automated predictive library\n",
    "    - Use the application’s automated analytics engine and data mining capabilities on your data stored in SAP HANA.\n",
    "- R integration\n",
    "    - Leverage tight integration with R to enable a large number of algorithms and custom R scripts for analyzing your data.\n",
    "\n",
    "#### Evaluation Version\n",
    "You can have a full evaluation version of SAP Predictive Analytics from https://www.sap.com/cmp/ft/crm-xm15-dwn-an001/index.html\n",
    "\n",
    "#### User Interfaces and Rapid prototyping: SAP BUILD platform\n",
    "\n",
    "\n",
    "SAP Cloud Platform [BUILD](https://www.build.me/splashapp/) allows you to collaboratively develop prototypes with your project team, engage end-users for feedback, or jumpstart your designs with one of many prototype examples from the gallery – all while learning the design process. Discover how Build’s comprehensive tools are the next frontier in creating design-led applications.\n",
    "is a web application that makes creating and designing user interfaces a very easy task, just drag and drop the components and BUILD will handle source code generation.\n",
    "\n",
    "##### What is Build?\n",
    "BUILD is a free cloud-based solution for developing prototypes of applications. \n",
    "The Key capabilities include: \n",
    "* Prototyping for Apps: For prototyping and modeling you can use a set of user interface element and integrate your own data.  \n",
    "* Integrated User Research: Verbal and nonverbal feedback from endusers is important to improve your application. To realize this, BUILD offers the opportunity to create a study. \n",
    "* Gallery of Application Prototypes: Get inspired by existent prototypes or published prototypes from other users.\n",
    "* Online Learning, Best Practice: This strong tool guides you step by step through the design and prototype process. \n",
    "\n",
    "![design-thinking](images/steps.png)\n",
    "\n",
    "Also, you can take part in eLearning about design-thinking methodologies. If you want support to general questions or need more information about user interface components, templates or for example functionalities look to the [Help Center](https://sap.github.io/BUILD_User_Assistance/build/external/67119e080abe42cab7bc1b32f5b953ca.html) of BUILD. \n",
    "\n",
    "##### Protoyping steps\n",
    "###### Create Project\n",
    "After logging into BUILD, open a new project, enter a name and description and choose between the options: \n",
    "* Create a persona\n",
    "* Start prototyping\n",
    "* Create a study\n",
    "* Upload file\n",
    "* Invite team.\n",
    "\n",
    "###### Create Prototype \n",
    "Select the first page of your prototype; for example Freestyle Page, Responsive Page or Master Detail Page.\n",
    "\n",
    "* Freestyle pages: Here you can add components without positioning constraints. Make sure that you select the device you want to create the app for.\n",
    "* Responsive pages: The size of the components adapts automatically to the different devices. \n",
    "\n",
    "###### Add Pages\n",
    "![Add page](images/add.png)\n",
    "To add a page, click the plus in the **Outline** section in the left sidebar\n",
    "To rename, delete or duplicate a page make a right click on the page you want to edit. \n",
    "\n",
    "###### Import Data \n",
    "One option to import data into your project is to open the tab **Data** and drag the files directly to the panel. \n",
    "The same you can do with the images by using the tab **Image**. \n",
    "![Add page](images/import.png)\n",
    "\n",
    "###### Add components\n",
    "In tab **Controls** you can find a list of all components\n",
    "![Add page](images/controls.png)\n",
    "* Insert a control using drag and drop feature on the page you want.\t\n",
    "* Click on the component and edit it by using the right sidebar. \n",
    "\n",
    "If it is necessary that a component gets specific data, you can do so by going to tab **Data**, select the data you want to insert into the component by using drag and drop.\n",
    "\n",
    "\n",
    "###### Preview your Prototype \n",
    "Preview your pages by clicking on the \"view\" icon. You can also change the device and the layout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Data sets\n",
    "### Description\n",
    "\n",
    "In the context of the hackathon, we have prepared the following data sets\n",
    "- Villefranche sur mer Hydrology since 2004 (chlorophyll level, temperature, depth, oxygen level, ..etc)\n",
    "- Plankton Biomass abundance in Villefranche sur mer\n",
    "- Maritime traffic in Mediterranean sea\n",
    "- Maritime Accidents in Mediterranean Sea\n",
    "- Overfishing in the Mediterranean sea\n",
    "- Annotated Plankton images\n",
    "- Annotated plankton drawings\n",
    "- Climate change indicators:\n",
    "    - Average Global Sea Surface Temperature from 1880 until 2015\n",
    "    - Global Average Absolute Sea Level Change from 1880 until 2015\n",
    "    \n",
    "#### Hydrology measurements in Villefranche sur Mer\n",
    "\n",
    "Hydrology is the scientific study of the movement, distribution, and quality of water on Earth and other planets, including the water cycle, water resources and environmental watershed sustainability. A practitioner of hydrology is a hydrologist, working within the fields of earth or environmental science, physical geography, geology or civil and environmental engineering. Using various analytical methods and scientific techniques, they collect and analyze data to help solve water related problems such as environmental preservation, natural disasters, and water management.\n",
    "\n",
    "Hydrology subdivides into surface water hydrology, groundwater hydrology (hydrogeology), and marine hydrology. Domains of hydrology include hydrometeorology, surface hydrology, hydrogeology, drainage-basin management and water quality, where water plays the central role.\n",
    "\n",
    "The file **hydro_vlfr.csv** represents the hydrology of villefranche sur mer as shown in http://www.obs-vlfr.fr/data/view/radehydro/std/. These data correspont to the depth between 1 and 50m.\n",
    "\n",
    "\n",
    "##### Featureset Exploration\n",
    "* **date**: Observation date\n",
    "* **depth**: Depth\n",
    "* **Chlorophyll a [µg/L]**: Level of Chlorophyll\n",
    "* **Nitrate [µmol/L]**: Level of Nitrate\n",
    "* **Oxygen (Winkler) [mL/L]**: Level of Oxygen\n",
    "* **Particulate organic carbon [µg/L]**: concentration of particuple organic carbon\n",
    "* **Particulate organic nitrogen [µg/L]**: concentration of particuple organic nitrogic\n",
    "* **Phaeopigments [µg/L]**: Level of Phaeopigments\n",
    "* **Phosphate [µmol/L]**: Level of Phosphate\n",
    "* **Pot. density [kg/m3 - 1000]**\n",
    "* **Salinity**: salinity\n",
    "* **Silicate [µmol/L]**: Level of Silicate\n",
    "* **Temperature [ºC]**: Temperature\n",
    "\n",
    "\n",
    "#### Biomass Abundance in Villefranche sur Mer\n",
    "\n",
    "The file **WP2_vlfr.csv** contains the data that are displayed in \n",
    "these data describe the abundance of plankton in Villefranche. For each taxinomic group, there are 3 variables:\n",
    "* **ESD**: Equivalent Spherical Diameter - the avaergae size of ogranisms in a week.\n",
    "* **concentration**: Number of organisms per m3\n",
    "* **biovolume**: living organisms volume per m3\n",
    "\n",
    "The data correspond to groups and all sub-groups, for example \"living\" represents the average size, teh concentration and the volume of all the living organisms during the week of observation.\n",
    "\n",
    "\n",
    "##### Featureset Exploration\n",
    "* **date**: observation date\n",
    "* **id**: observation's id\n",
    "* **esd**: equivalent spherical diameter - average size of the organism in a week\n",
    "* **concentration**: number of organism of this taxinomic group per m3\n",
    "* **biovolume**: living organism volume per m3 of the taxinomic group\n",
    "* **name**: name of the taxinomic group\n",
    "\n",
    "#### Maritime Traffic in Mediterranean \n",
    "\n",
    "Daily, an average of 150 000 ships are transitting in the world, the file **traffic.zip** contains the list of all the ships present in the Mediterranena sea on Novermber's 22nd.\n",
    "\n",
    "#### Overfishing in Mediterranean Sea\n",
    "\n",
    "The file **fao.csv** contains the volume of fish catches landed by country or territory of capture, by species or a higher taxonomic level, in the Mediterranean sea, and year for all commercial, industrial, recreational and subsistence purposes from 1970 to 2015.\n",
    "\n",
    "#### Maritime Accidents in Mediterranean Sea\n",
    "\n",
    "The file **accidents.csv** contains the known maritime accidents that happened in the mediterranean sea. Those accidents include:\n",
    "* Blow-out\n",
    "* Cargo transfer failure\n",
    "* Collision\n",
    "* Contact\n",
    "* Engine or machinery breakdown\n",
    "* Fire or explosion\n",
    "* Foundering\n",
    "* Grounding\n",
    "* Hull structrual failure\n",
    "* Installation structural failure\n",
    "* Oil or gaz leak\n",
    "\n",
    "#### Annotated plankton images\n",
    "For this challenge, OOV scientists have prepared a large collection of labeled images, approximately 30k of which are provided as a training set. Each raw image was run through an automatic process to extract regions of interest, resulting in smaller images that contain a single organism/entity.\n",
    "\n",
    "There are many different species, ranging from the smallest single-celled protists to copepods, larval fish, and larger jellies.\n",
    "Representatives from each taxon can have any orientation within 3-D space.\n",
    "The ocean is replete with detritus (often decomposing plant or animal matter that scientists like to call “whale snot”) and fecal pellets that have no taxonomic identification but are important in other marine processes.\n",
    "Some images are so noisy or ambiguous that experts have a difficult time labeling them. Some amount of noise in the ground truth is thus inevitable.\n",
    "The presence of \"unknown\" classes require models to handle the special cases of unidentifiable objects.\n",
    "![plankton](https://kaggle2.blob.core.windows.net/competitions/kaggle/3978/media/plankton%20schmorgasborg.jpg)\n",
    "\n",
    "The file **train.zip** contains labeled images for training. Each folder represents a class. Images within the folder belong to that class. Classes were chosen by the OOV experts and represent scientifically meaningful groupings of organisms and objects. The file contains also a special folder **info** which contains TSV files that contain contextual information about each of the images.  These TSV files contain many information about the image (acquisition date, annotator, shape and size of the image, depth, temperature, latitude, longitude, ... etc)\n",
    "The list of classes included is the following:\n",
    "\n",
    "```\n",
    "Abylopsis tetragona_eudoxie\n",
    "Abylopsis tetragona_gonophore\n",
    "Abylopsis tetragona_nectophore\n",
    "Actinopterygii_egg\n",
    "Agalma elegans_siphonula\n",
    "Annelida_larvae\n",
    "Annelida_part\n",
    "Appendicularia_head\n",
    "Appendicularia_Oikopleuridae\n",
    "Appendicularia_tail\n",
    "artefact_badfocus\n",
    "artefact_bubble\n",
    "Augaptilidae_Haloptilus\n",
    "Brachyura_like\n",
    "Brachyura_megalopa\n",
    "Bryozoa_cyphonaute\n",
    "Calanoida_Acartiidae\n",
    "Calanoida_Calanidae\n",
    "Calanoida_Candaciidae\n",
    "Calanoida_Centropagidae\n",
    "Calanoida_Temoridae\n",
    "Campanulariidae_Obelia\n",
    "Cavolinia inflexa_egg\n",
    "Cavolinia_Cavolinia inflexa\n",
    "Ceratiaceae_Neoceratium\n",
    "Chaetognatha_head\n",
    "Chaetognatha_tail\n",
    "Cirripedia_nauplii\n",
    "Clio_Clio pyramidata\n",
    "Cnidaria_Hydrozoa\n",
    "Cnidaria_part\n",
    "Copepoda_Calanoida\n",
    "Copepoda_dead\n",
    "Copepoda_Harpacticoida\n",
    "Copepoda_multiple\n",
    "Copepoda_Poecilostomatoida\n",
    "Creseis_Creseis acicula\n",
    "Crustacea_nauplii\n",
    "Crustacea_part\n",
    "Cyclopoida_Oithonidae\n",
    "Decapoda_zoea\n",
    "detritus_fiber\n",
    "Diphyidae_eudoxie\n",
    "Diphyidae_gonophore\n",
    "Diphyidae_nectophore\n",
    "Eukaryota_Harosa\n",
    "Eumalacostraca_Amphipoda\n",
    "Euphausiacea_calyptopsis\n",
    "Flaccisagitta_Flaccisagitta enflata\n",
    "Fritillariidae_Fritillaria\n",
    "Galatheidae_zoea\n",
    "Gnathostomata_Actinopterygii\n",
    "Harpacticoida_Euterpina\n",
    "Hexacorallia_Actiniaria\n",
    "Hippopodiidae_nectophore\n",
    "Maxillopoda_Copepoda\n",
    "Metazoa_Annelida\n",
    "Metazoa_Chaetognatha\n",
    "Metazoa_Echinodermata\n",
    "Metazoa_Mollusca\n",
    "Metridinidae_Pleuromamma\n",
    "Mollusca_Bivalvia\n",
    "not-living_artefact\n",
    "not-living_detritus\n",
    "Oikopleuridae_Oikopleura\n",
    "Oligostraca_Ostracoda\n",
    "other_egg\n",
    "other_multiple\n",
    "other_othertocheck\n",
    "other_seaweed\n",
    "Penaeidae_protozoea\n",
    "Penilia_Penilia avirostris\n",
    "Physonectae_nectophore\n",
    "Podonidae_Evadne\n",
    "Podonidae_Podon\n",
    "Poecilostomatoida_Corycaeidae\n",
    "Poecilostomatoida_Oncaeidae\n",
    "Poecilostomatoida_Sapphirinidae\n",
    "Rhopalonematidae_Aglaura\n",
    "Rhopalonematidae_Rhopalonema\n",
    "Salpida_colony\n",
    "Salpida_larvae\n",
    "Scyphozoa_ephyra\n",
    "Siphonophorae_Physonectae\n",
    "Siphonophorae_siphosome\n",
    "Styliola_Styliola subula\n",
    "Thaliacea_Doliolida\n",
    "Thaliacea_Pyrosomatida\n",
    "Thaliacea_Salpida\n",
    "Thecofilosea_Phaeodaria\n",
    "Thecosomata_Creseidae\n",
    "Thecosomata_Limacinidae\n",
    "Thecostraca_Cirripedia\n",
    "Tunicata_Appendicularia\n",
    "\n",
    "```\n",
    "The file **test.zip** contains the test set images, for which you must predict class probabilities. \n",
    "\n",
    "**plankton_identification.pdf** is provided as a rough guide to understand relationships between the classes. The tree-like diagram indicates morphological and biological connections between groups. Dashed lines indicate a weak(er) relationship and solid lines a stronger relationship.\n",
    "\n",
    "#### Annotated plankton drawings\n",
    "\n",
    "The file **drawing-train.zip** contains the training set for the drawings. Each folder represents a class. Images within the folder belong to that class. Classes represent scientifically meaningful groupings of organisms and objects (see the below FAQs). \n",
    "\n",
    "The file **drawing-test.zip** contains the test set drawings.\n",
    "\n",
    "#### Average Global Sea Surface Temperature\n",
    "Sea surface temperature—the temperature of the water at the ocean surface—is an important physical attribute of the world’s oceans. The surface temperature of the world’s oceans varies mainly with latitude, with the warmest waters generally near the equator and the coldest waters in the Arctic and Antarctic regions. As the oceans absorb more heat, sea surface temperature increases and the ocean circulation patterns that transport warm and cold water around the globe change.\n",
    "\n",
    "Changes in sea surface temperature can alter marine ecosystems in several ways. For example, variations in ocean temperature can affect what species of plants, animals, and microbes are present in a location, alter migration and breeding patterns, threaten sensitive ocean life such as corals, and change the frequency and intensity of harmful algal blooms such as “red tide.”Over the long term, increases in sea surface temperature could also reduce the circulation patterns that bring nutrients from the deep sea to surface waters. Changes in reef habitat and nutrient supply could dramatically alter ocean ecosystems and lead to declines in fish populations, which in turn could affect people who depend on fishing for food or jobs.\n",
    "\n",
    "Because the oceans continuously interact with the atmosphere, sea surface temperature can also have profound effects on global climate. Increases in sea surface temperature have led to an increase in the amount of atmospheric water vapor over the oceans. This water vapor feeds weather systems that produce precipitation, increasing the risk of heavy rain and snow (see the Heavy Precipitation and Tropical Cyclone Activity indicators). Changes in sea surface temperature can shift storm tracks, potentially contributing to droughts in some areas. Increases in sea surface temperature are also expected to lengthen the growth season for certain bacteria that can contaminate seafood and cause foodborne illnesses, thereby increasing the risk of health effects.\n",
    "\n",
    "##### Featureset Exploration\n",
    "* **Year**: Year\n",
    "* **Annual anomaly**: Temperature (°F)\n",
    "* **Lower 95% confidence interval**: lower 95% confidence interval\n",
    "* **Upper 95% confidence interval**: upper 95% confidence interval\n",
    "\n",
    "#### Global Average Absolute Sea Level Change\n",
    "As the temperature of the Earth changes, so does sea level. Temperature and sea level are linked for two main reasons:\n",
    "Changes in the volume of water and ice on land (namely glaciers and ice sheets) can increase or decrease the volume of water in the ocean (see the Glaciers indicator).\n",
    "\n",
    "As water warms, it expands slightly—an effect that is cumulative over the entire depth of the oceans (see the Ocean Heat indicator).\n",
    "\n",
    "Changing sea levels can affect human activities in coastal areas. Rising sea level inundates low-lying wetlands and dry land, erodes shorelines, contributes to coastal flooding, and increases the flow of salt water into estuaries and nearby groundwater aquifers. Higher sea level also makes coastal infrastructure more vulnerable to damage from storms.\n",
    "\n",
    "The sea level changes that affect coastal systems involve more than just expanding oceans, however, because the Earth’s continents can also rise and fall relative to the oceans. Land can rise through processes such as sediment accumulation (the process that built the Mississippi River delta) and geological uplift (for example, as glaciers melt and the land below is no longer weighed down by heavy ice). In other areas, land can sink because of erosion, sediment compaction, natural subsidence (sinking due to geologic changes), groundwater withdrawal, or engineering projects that prevent rivers from naturally depositing sediments along their banks. Changes in ocean currents such as the Gulf Stream can also affect sea levels by pushing more water against some coastlines and pulling it away from others, raising or lowering sea levels accordingly.\n",
    "\n",
    "Scientists account for these types of changes by measuring sea level change in two different ways. Relative sea level change refers to how the height of the ocean rises or falls relative to the land at a particular location. In contrast, absolute sea level change refers to the height of the ocean surface above the center of the earth, without regard to whether nearby land is rising or falling.\n",
    "\n",
    "\n",
    "Absolute sea level trends were provided by Australia’s Commonwealth Scientific and Industrial Research Organisation and the National Oceanic and Atmospheric Administration. These data are based on measurements collected by satellites and tide gauges. Relative sea level data are available from the National Oceanic and Atmospheric Administration, which publishes an interactive online map (http://tidesandcurrents.noaa.gov/sltrends/sltrends.shtml) with links to detailed data for each tide gauge.\n",
    "\n",
    "\n",
    "##### Featureset Exploration\n",
    "* **Year**: Year\n",
    "* **CSIRO - Adjusted sea level (inches)**: Adjusted see level by CSIRO - Commonwealth Scientific and Industrial Research Organisation (Australia)\n",
    "* **CSIRO - Lower error bound (inches)**: Lower see level by CSIRO - Commonwealth Scientific and Industrial Research Organisation (Australia)\n",
    "* **CSIRO - Upper error bound (inches)**: Upper see level by CSIRO - Commonwealth Scientific and Industrial Research Organisation (Australia)\n",
    "* **NOAA - Adjusted sea level (inches)**: Adjusted see level by NOAA - National Oceanic and Atmospheric Administration (US)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will go step-by-step through a simple model to distinguish different types of plankton and demonstrate some tools for exploring the image dataset. We will start by going through an example of one image to show how you could choose to develop a metric based on the shape of the object within the image. First, we import the necessary modules from scikit-image, matplotlib, scikit-learn, and numpy. If you don't currently have python installed, you can get the Anaconda distribution that includes all of the referenced packages below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import libraries for image analysis\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "import glob\n",
    "import os\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import StratifiedKFold as KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from pylab import cm\n",
    "from skimage import segmentation\n",
    "from skimage.morphology import watershed\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "# make graphics inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is organized in a series of subdirectories that contain examples for the each class of interest. We will store the list of directory names to aid in labelling the data classes for training and testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the classnames from the directory structure\n",
    "directory_names = list(set(glob.glob(os.path.join(\"competition_data\",\"train\", \"*\"))\\\n",
    " ).difference(set(glob.glob(os.path.join(\"competition_data\",\"train\",\"*.*\")))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will develop our feature on one image example and examine each step before calculating the feature across the distribution of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example image\n",
    "# This example was chosen for because it has two noncontinguous pieces\n",
    "# that will make the segmentation example more illustrative\n",
    "example_file = glob.glob(os.path.join(directory_names[5],\"*.jpg\"))[9]\n",
    "print example_file\n",
    "im = imread(example_file, as_grey=True)\n",
    "plt.imshow(im, cmap=cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Images\n",
    "\n",
    "To create the features of interest, we will need to prepare the images by completing a few preprocessing procedures. We will step through some common image preprocessing actions: thresholding the images, segmenting the images, and extracting region properties. Using the region properties, we will create features based on the intrinsic properties of the classes, which we expect will allow us discriminate between them. Let's walk through the process of adding one such feature for the ratio of the width by length of the object of interest.\n",
    "\n",
    "First, we begin by thresholding the image on the the mean value. This will reduce some of the noise in the image. Then, we apply a three step segmentation process: first we dilate the image to connect neighboring pixels, then we calculate the labels for connected regions, and finally we apply the original threshold to the labels to label the original, undilated regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we threshold the image by only taking values greater than the mean to reduce noise in the image\n",
    "# to use later as a mask\n",
    "f = plt.figure(figsize=(12,3))\n",
    "imthr = im.copy()\n",
    "imthr = np.where(im > np.mean(im),0.,1.0)\n",
    "sub1 = plt.subplot(1,4,1)\n",
    "plt.imshow(im, cmap=cm.gray)\n",
    "sub1.set_title(\"Original Image\")\n",
    "\n",
    "sub2 = plt.subplot(1,4,2)\n",
    "plt.imshow(imthr, cmap=cm.gray_r)\n",
    "sub2.set_title(\"Thresholded Image\")\n",
    "\n",
    "imdilated = morphology.dilation(imthr, np.ones((4,4)))\n",
    "sub3 = plt.subplot(1, 4, 3)\n",
    "plt.imshow(imdilated, cmap=cm.gray_r)\n",
    "sub3.set_title(\"Dilated Image\")\n",
    "\n",
    "labels = measure.label(imdilated)\n",
    "labels = imthr*labels\n",
    "labels = labels.astype(int)\n",
    "sub4 = plt.subplot(1, 4, 4)\n",
    "sub4.set_title(\"Labeled Image\")\n",
    "plt.imshow(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the image segmented into different parts, we would like to choose the largest non-background part to compute our metric. We would like to select the largest segment as the likely object of interest for classification purposes. We loop through the available regions and select the one with the largest area. There are many properties available within the regions that you can explore for creating new features. Look at the documentation for regionprops for inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate common region properties for each region within the segmentation\n",
    "regions = measure.regionprops(labels)\n",
    "# find the largest nonzero region\n",
    "def getLargestRegion(props=regions, labelmap=labels, imagethres=imthr):\n",
    "    regionmaxprop = None\n",
    "    for regionprop in props:\n",
    "        # check to see if the region is at least 50% nonzero\n",
    "        if sum(imagethres[labelmap == regionprop.label])*1.0/regionprop.area < 0.50:\n",
    "            continue\n",
    "        if regionmaxprop is None:\n",
    "            regionmaxprop = regionprop\n",
    "        if regionmaxprop.filled_area < regionprop.filled_area:\n",
    "            regionmaxprop = regionprop\n",
    "    return regionmaxprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for our test image are shown below. The segmentation picked one region and we use that region to calculate our ratio metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regionmax = getLargestRegion()\n",
    "plt.imshow(np.where(labels == regionmax.label,1.0,0.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(regionmax.minor_axis_length/regionmax.major_axis_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we collect the previous steps together in a function to make it easily repeatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMinorMajorRatio(image):\n",
    "    image = image.copy()\n",
    "    # Create the thresholded image to eliminate some of the background\n",
    "    imagethr = np.where(image > np.mean(image),0.,1.0)\n",
    "\n",
    "    #Dilate the image\n",
    "    imdilated = morphology.dilation(imagethr, np.ones((4,4)))\n",
    "\n",
    "    # Create the label list\n",
    "    label_list = measure.label(imdilated)\n",
    "    label_list = imagethr*label_list\n",
    "    label_list = label_list.astype(int)\n",
    "    \n",
    "    region_list = measure.regionprops(label_list)\n",
    "    maxregion = getLargestRegion(region_list, label_list, imagethr)\n",
    "    \n",
    "    # guard against cases where the segmentation fails by providing zeros\n",
    "    ratio = 0.0\n",
    "    if ((not maxregion is None) and  (maxregion.major_axis_length != 0.0)):\n",
    "        ratio = 0.0 if maxregion is None else  maxregion.minor_axis_length*1.0 / maxregion.major_axis_length\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Training Data\n",
    "\n",
    "With our code for the ratio of minor to major axis, let's add the raw pixel values to the list of features for our dataset. In order to use the pixel values in a model for our classifier, we need a fixed length feature vector, so we will rescale the images to be constant size and add the fixed number of pixels to the feature vector.\n",
    "\n",
    "To create the feature vectors, we will loop through each of the directories in our training data set and then loop over each image within that class. For each image, we will rescale it to 25 x 25 pixels and then add the rescaled pixel values to a feature vector, X. The last feature we include will be our width-to-length ratio. We will also create the class label in the vector y, which will have the true class label for each row of the feature vector, X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rescale the images and create the combined metrics and training labels\n",
    "\n",
    "#get the total training images\n",
    "numberofImages = 0\n",
    "for folder in directory_names:\n",
    "    for fileNameDir in os.walk(folder):   \n",
    "        for fileName in fileNameDir[2]:\n",
    "             # Only read in the images\n",
    "            if fileName[-4:] != \".jpg\":\n",
    "              continue\n",
    "            numberofImages += 1\n",
    "\n",
    "# We'll rescale the images to be 25x25\n",
    "maxPixel = 25\n",
    "imageSize = maxPixel * maxPixel\n",
    "num_rows = numberofImages # one row for each image in the training dataset\n",
    "num_features = imageSize + 1 # for our ratio\n",
    "\n",
    "# X is the feature vector with one row of features per image\n",
    "# consisting of the pixel values and our metric\n",
    "X = np.zeros((num_rows, num_features), dtype=float)\n",
    "# y is the numeric class label \n",
    "y = np.zeros((num_rows))\n",
    "\n",
    "files = []\n",
    "# Generate training data\n",
    "i = 0    \n",
    "label = 0\n",
    "# List of string of class names\n",
    "namesClasses = list()\n",
    "\n",
    "print \"Reading images\"\n",
    "# Navigate through the list of directories\n",
    "for folder in directory_names:\n",
    "    # Append the string class name for each class\n",
    "    currentClass = folder.split(os.pathsep)[-1]\n",
    "    namesClasses.append(currentClass)\n",
    "    for fileNameDir in os.walk(folder):   \n",
    "        for fileName in fileNameDir[2]:\n",
    "            # Only read in the images\n",
    "            if fileName[-4:] != \".jpg\":\n",
    "              continue\n",
    "            \n",
    "            # Read in the images and create the features\n",
    "            nameFileImage = \"{0}{1}{2}\".format(fileNameDir[0], os.sep, fileName)            \n",
    "            image = imread(nameFileImage, as_grey=True)\n",
    "            files.append(nameFileImage)\n",
    "            axisratio = getMinorMajorRatio(image)\n",
    "            image = resize(image, (maxPixel, maxPixel))\n",
    "            \n",
    "            # Store the rescaled image pixels and the axis ratio\n",
    "            X[i, 0:imageSize] = np.reshape(image, (1, imageSize))\n",
    "            X[i, imageSize] = axisratio\n",
    "            \n",
    "            # Store the classlabel\n",
    "            y[i] = label\n",
    "            i += 1\n",
    "            # report progress for each 5% done  \n",
    "            report = [int((j+1)*num_rows/20.) for j in range(20)]\n",
    "            if i in report: print np.ceil(i *100.0 / num_rows), \"% done\"\n",
    "    label += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Width-to-Length Ratio Class Separation\n",
    "\n",
    "Now that we have calculated the width-to-length ratio metric for all the images, we can look at the class separation to see how well our feature performs. We'll compare pairs of the classes' distributions by plotting each pair of classes. While this will not cover the whole space of hundreds of possible combinations, it will give us a feel for how similar or dissimilar different classes are in this feature, and the class distributions should be comparable across subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop through the classes two at a time and compare their distributions of the Width/Length Ratio\n",
    "\n",
    "#Create a DataFrame object to make subsetting the data on the class \n",
    "df = pd.DataFrame({\"class\": y[:], \"ratio\": X[:, num_features-1]})\n",
    "\n",
    "f = plt.figure(figsize=(30, 20))\n",
    "#we suppress zeros and choose a few large classes to better highlight the distributions.\n",
    "df = df.loc[df[\"ratio\"] > 0]\n",
    "minimumSize = 20 \n",
    "counts = df[\"class\"].value_counts()\n",
    "largeclasses = [int(x) for x in list(counts.loc[counts > minimumSize].index)]\n",
    "# Loop through 40 of the classes \n",
    "for j in range(0,40,2):\n",
    "    subfig = plt.subplot(4, 5, j/2 +1)\n",
    "    # Plot the normalized histograms for two classes\n",
    "    classind1 = largeclasses[j]\n",
    "    classind2 = largeclasses[j+1]\n",
    "    n, bins,p = plt.hist(df.loc[df[\"class\"] == classind1][\"ratio\"].values,\\\n",
    "                         alpha=0.5, bins=[x*0.01 for x in range(100)], \\\n",
    "                         label=namesClasses[classind1].split(os.sep)[-1], normed=1)\n",
    "\n",
    "    n2, bins,p = plt.hist(df.loc[df[\"class\"] == (classind2)][\"ratio\"].values,\\\n",
    "                          alpha=0.5, bins=bins, label=namesClasses[classind2].split(os.sep)[-1],normed=1)\n",
    "    subfig.set_ylim([0.,10.])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel(\"Width/Length Ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the (truncated) figure above, you will see some cases where the classes are well separated and others were they are not. It is typical that one single feature will not allow you to completely separate more than thirty distinct classes. You will need to be creative in coming up with additional metrics to discriminate between all the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification\n",
    "\n",
    "We choose a random forest model to classify the images. Random forests perform well in many classification tasks and have robust default settings. We will give a brief description of a random forest model so that you can understand its two main free parameters: n_estimators and max_features.\n",
    "\n",
    "A random forest model is an ensemble model of n_estimators number of decision trees. During the training process, each decision tree is grown automatically by making a series of conditional splits on the data. At each split in the decision tree, a random sample of max_features number of features is chosen and used to make a conditional decision on which of the two nodes that the data will be grouped in. The best condition for the split is determined by the split that maximizes the class purity of the nodes directly below. The tree continues to grow by making additional splits until the leaves are pure or the leaves have less than the minimum number of samples for a split (in sklearn default for min_samples_split is two data points). The final majority class purity of the terminal nodes of the decision tree are used for making predictions on what class a new data point will belong. Then, the aggregate vote across the forest determines the class prediction for new samples.\n",
    "\n",
    "With our training data consisting of the feature vector X and the class label vector y, we will now calculate some class metrics for the performance of our model, by class and overall. First, we train the random forest on all the available data and let it perform the 5-fold cross validation. Then we perform the cross validation using the KFold method, which splits the data into train and test sets, and a classification report. The classification report provides a useful list of performance metrics for your classifier vs. the internal metrics of the random forest module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Training\")\n",
    "# n_estimators is the number of decision trees\n",
    "# max_features also known as m_try is set to the default value of the square root of the number of features\n",
    "clf = RF(n_estimators=100, n_jobs=3);\n",
    "scores = cross_validation.cross_val_score(clf, X, y, cv=5, n_jobs=1);\n",
    "print(\"Accuracy of all classes\")\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(y, n_folds=5)\n",
    "y_pred = y * 0\n",
    "for train, test in kf:\n",
    "    X_train, X_test, y_train, y_test = X[train,:], X[test,:], y[train], y[test]\n",
    "    clf = RF(n_estimators=100, n_jobs=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred[test] = clf.predict(X_test)\n",
    "print(classification_report(y, y_pred, target_names=namesClasses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current model, while somewhat accurate overall, doesn't do well for all classes, including the shrimp caridean, stomatopod, or hydromedusae tentacles classes. For others it does quite well, getting many of the correct classifications for trichodesmium_puff and copepod_oithona_eggs classes. The metrics shown above for measuring model performance include precision, recall, and f1-score. The precision metric gives probability that a chosen class is correct, (true positives / (true positive + false positives)), while recall measures the ability of the model correctly classify examples of a given class, (true positives / (false negatives + true positives)). The F1 score is the geometric average of the precision and recall.\n",
    "\n",
    "The competition scoring uses a multiclass log-loss metric to compute your overall score. In the next steps, we define the multiclass log-loss function and compute your estimated score on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiclass_log_loss(y_true, y_pred, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    https://www.kaggle.com/wiki/MultiClassLogLoss\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_samples]\n",
    "            true class, intergers in [0, n_classes - 1)\n",
    "    y_pred : array, shape = [n_samples, n_classes]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "    \"\"\"\n",
    "    predictions = np.clip(y_pred, eps, 1 - eps)\n",
    "\n",
    "    # normalize row sums to 1\n",
    "    predictions /= predictions.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    actual = np.zeros(y_pred.shape)\n",
    "    n_samples = actual.shape[0]\n",
    "    actual[np.arange(n_samples), y_true.astype(int)] = 1\n",
    "    vectsum = np.sum(actual * np.log(predictions))\n",
    "    loss = -1.0 / n_samples * vectsum\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the probability predictions for computing the log-loss function\n",
    "kf = KFold(y, n_folds=5)\n",
    "# prediction probabilities number of samples, by number of classes\n",
    "y_pred = np.zeros((len(y),len(set(y))))\n",
    "for train, test in kf:\n",
    "    X_train, X_test, y_train, y_test = X[train,:], X[test,:], y[train], y[test]\n",
    "    clf = RF(n_estimators=100, n_jobs=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred[test] = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiclass_log_loss(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiclass log loss function is an classification error metric that heavily penalizes you for being both confident (either predicting very high or very low class probability) and wrong. Throughout the competition you will want to check that your model improvements are driving this loss metric lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to Go From Here\n",
    "Now that you've made a simple metric, created a model, and examined the model's performance on the training data, the next step is to make improvements to your model to make it more competitive. The random forest model we created does not perform evenly across all classes and in some cases fails completely. By creating new features and looking at some of your distributions for the problem classes directly, you can identify features that specifically help separate those classes from the others. You can add new metrics by considering other image properties, stratified sampling, transformations, or other models for the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
